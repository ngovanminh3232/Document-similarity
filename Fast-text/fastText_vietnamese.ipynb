{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Cài thêm thư viện"
      ],
      "metadata": {
        "id": "UApIcUjmFO5W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fasttext\n",
        "!pip install underthesea"
      ],
      "metadata": {
        "id": "nJTMBsXlg4k-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12eac047-8c01-4ef3-8b84-b9e3c5f79173"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting fasttext\n",
            "  Downloading fasttext-0.9.2.tar.gz (68 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.8/68.8 KB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pybind11>=2.2\n",
            "  Using cached pybind11-2.10.3-py3-none-any.whl (222 kB)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from fasttext) (57.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from fasttext) (1.21.6)\n",
            "Building wheels for collected packages: fasttext\n",
            "  Building wheel for fasttext (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fasttext: filename=fasttext-0.9.2-cp38-cp38-linux_x86_64.whl size=3127972 sha256=7f35729f8861a1e9cd519dd8129cc90d5864e079960c9b484c6c699170f3fa0f\n",
            "  Stored in directory: /root/.cache/pip/wheels/93/61/2a/c54711a91c418ba06ba195b1d78ff24fcaad8592f2a694ac94\n",
            "Successfully built fasttext\n",
            "Installing collected packages: pybind11, fasttext\n",
            "Successfully installed fasttext-0.9.2 pybind11-2.10.3\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting underthesea\n",
            "  Downloading underthesea-6.0.1-py3-none-any.whl (11.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.0/11.0 MB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting underthesea-core==0.0.5a2\n",
            "  Downloading underthesea_core-0.0.5_alpha.2-cp38-cp38-manylinux2010_x86_64.whl (591 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m591.3/591.3 KB\u001b[0m \u001b[31m42.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from underthesea) (2.25.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from underthesea) (4.64.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.8/dist-packages (from underthesea) (6.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.8/dist-packages (from underthesea) (3.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from underthesea) (1.2.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.8/dist-packages (from underthesea) (1.0.2)\n",
            "Requirement already satisfied: Click>=6.0 in /usr/local/lib/python3.8/dist-packages (from underthesea) (7.1.2)\n",
            "Collecting python-crfsuite>=0.9.6\n",
            "  Downloading python_crfsuite-0.9.8-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m61.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.8/dist-packages (from nltk->underthesea) (2022.6.2)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->underthesea) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->underthesea) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->underthesea) (1.24.3)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->underthesea) (4.0.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->underthesea) (1.7.3)\n",
            "Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->underthesea) (1.21.6)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->underthesea) (3.1.0)\n",
            "Installing collected packages: underthesea-core, python-crfsuite, underthesea\n",
            "Successfully installed python-crfsuite-0.9.8 underthesea-6.0.1 underthesea-core-0.0.5a2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tải model vietnamese từ fastext"
      ],
      "metadata": {
        "id": "r6gxOawOFT5L"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VS184xX3f-wS",
        "outputId": "d7f5b17c-df5f-4ae6-f6cf-ca633f6c9383"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.vi.300.bin.gz\n",
            "To: /content/cc.vi.300.bin.gz\n",
            "100% 4.50G/4.50G [01:38<00:00, 45.6MB/s]\n"
          ]
        }
      ],
      "source": [
        "!gdown https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.vi.300.bin.gz"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tải stop-word để tiền xử lý"
      ],
      "metadata": {
        "id": "gjSvJr_SFXsV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown https://drive.google.com/uc?id=12D06zcJzNi5BepCpTDsyE0MdwVCKmsy8&export=download"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ad80orU7AdwY",
        "outputId": "7eede58f-b731-471f-9040-b87e650166f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=12D06zcJzNi5BepCpTDsyE0MdwVCKmsy8\n",
            "To: /content/vietnamese-stopwords.txt\n",
            "\r  0% 0.00/20.5k [00:00<?, ?B/s]\r100% 20.5k/20.5k [00:00<00:00, 9.56MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gunzip /content/cc.vi.300.bin.gz"
      ],
      "metadata": {
        "id": "yFHeT3t0iEPP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tải data từ 300 bài báo đã được cào sẵn về."
      ],
      "metadata": {
        "id": "M5iO69ioFfau"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown https://drive.google.com/uc?id=1ZAC3mLjoWprkvRTR61xmtBn9OseorpCh&export=download"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RgcEuBrz5k18",
        "outputId": "67c26957-1790-431b-c0fe-ff679e94bef5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1ZAC3mLjoWprkvRTR61xmtBn9OseorpCh\n",
            "To: /content/newpaper.csv\n",
            "\r  0% 0.00/1.29M [00:00<?, ?B/s]\r100% 1.29M/1.29M [00:00<00:00, 102MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import thư viện"
      ],
      "metadata": {
        "id": "AEICLIK8FpVd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import fasttext\n",
        "import fasttext.util\n",
        "model = fasttext.load_model('/content/cc.vi.300.bin')\n",
        "model.get_dimension()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xdQhO2PYgy7Z",
        "outputId": "4da4b95e-cf7a-4990-dfaa-0daf2928de28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "300"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Đọc dữ liệu đầu vào để so sánh"
      ],
      "metadata": {
        "id": "aGJFx0VxFtvS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "data = pd.read_csv(\"/content/newpaper.csv\")\n",
        "\n",
        "base_document = data['Document'][0]\n",
        "documents = data['Document'][:]\n"
      ],
      "metadata": {
        "id": "bxo_bISc7_y6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "data = pd.read_excel(\"/content/Book1.xlsx\")\n",
        "\n",
        "base_document = data['Document'][0]\n",
        "documents = data['Document'][:]\n"
      ],
      "metadata": {
        "id": "8__Gm47dm3dl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.get_nearest_neighbors('tuyệt_vời')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ACmljLEelVoF",
        "outputId": "8bb41fa1-73b7-40a3-f6b4-f58cd283b43d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0.7256906628608704, 'hoàn_hảo'),\n",
              " (0.7149642705917358, 'tuyệt_hảo'),\n",
              " (0.7065508365631104, 'tuyệt_diệu'),\n",
              " (0.6789242029190063, 'tuyêt_vời'),\n",
              " (0.6640727519989014, 'tuyệt'),\n",
              " (0.6614848375320435, 'thú_vị'),\n",
              " (0.6341797709465027, 'tốt'),\n",
              " (0.632213294506073, 'Tuyệt_vời'),\n",
              " (0.6304551362991333, 'tuyệt_vờ'),\n",
              " (0.6303631067276001, 'lý_tưởng')]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy import spatial\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "#Hàm tính độ tương đồng theo cosine\n",
        "def cosin_similarity(vector1, vector2):\n",
        "  return np.dot(vector1,vector2)/(np.linalg.norm(vector1)*np.linalg.norm(vector2))"
      ],
      "metadata": {
        "id": "nY6jAmX5rWBF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "from underthesea import word_tokenize\n",
        "\n",
        "def stopwords():\n",
        "    sw = []\n",
        "    with open(\"/content/vietnamese-stopwords.txt\", encoding='utf-8') as f:\n",
        "        lines = f.readlines()\n",
        "    for line in lines:\n",
        "        sw.append(line.replace(\"\\n\",\"\"))\n",
        "    return sw\n",
        "\n",
        "\n",
        "def preprocess(text):\n",
        "\t# Steps:\n",
        "\t# 1. lowercase\n",
        "\t# 2. Lammetize. (It does not stem. Try to preserve structure not to overwrap with potential acronym).\n",
        "\t# 3. Remove stop words.\n",
        "\t# 4. Remove punctuations.\n",
        "\t# 5. Remove character with the length size of 1.\n",
        "\n",
        "\tlowered = str.lower(str(text))\n",
        "\n",
        "\tstop_words = set(stopwords())\n",
        "\tword_tokens = word_tokenize(lowered)\n",
        "\n",
        "\twords = []\n",
        "\tfor w in word_tokens:\n",
        "\t\tif w not in stop_words:\n",
        "\t\t\tif w not in string.punctuation:\n",
        "\t\t\t\tif len(w) > 1:\n",
        "\t\t\t\t\twords.append(w)\n",
        "\n",
        "\treturn words\n"
      ],
      "metadata": {
        "id": "NmcJ9Yr9_yNj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generateVector(sentence):\n",
        "    return model.get_sentence_vector(sentence)"
      ],
      "metadata": {
        "id": "TQ5d9OLTmaHe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def word2vec_similarity(doc1, doc2):\n",
        "  doc1_process = str(preprocess(doc1))\n",
        "  doc2_process = str(preprocess(doc2))\n",
        "  doc1_vec = generateVector(doc1_process)\n",
        "  doc2_vec = generateVector(doc2_process)\n",
        "  scores =  cosin_similarity(doc1_vec,doc2_vec)\n",
        "\n",
        "  return scores"
      ],
      "metadata": {
        "id": "cpZkzy_Y4tSw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = []\n",
        "for i, document in enumerate(documents):\n",
        "  scores = word2vec_similarity(base_document, documents[i])\n",
        "  result.append({'index': i, 'score': scores})\n",
        "\n",
        "\t#Sort scores in decreasing order\n",
        "  result = sorted(result, key=lambda x: x['score'], reverse=True)\n",
        "print(list(result))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AeqGSOGU5WpW",
        "outputId": "45de334c-aeff-44da-dbe4-83d23138740d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'index': 0, 'score': 1.0000001}, {'index': 2, 'score': 0.99999696}, {'index': 1, 'score': 0.9998529}, {'index': 3, 'score': 0.98695534}]\n"
          ]
        }
      ]
    }
  ]
}